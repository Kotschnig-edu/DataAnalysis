{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis Assignment 1\n",
    "**Due Date:** December 14, 2025, 23:59  \n",
    "**Total Points:** 114 + 15 bonus points\n",
    "\n",
    "## Copyright and Fair Use\n",
    "\n",
    "This material, no matter whether in printed or electronic form, may be used for personal and non-commercial educational use only. Any reproduction of this material, no matter whether as a whole or in parts, no matter whether in printed or in electronic form, requires explicit prior acceptance of the authors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guidelines\n",
    "\n",
    "1. **DO NOT add or delete any cells (or modify cell IDs)**\n",
    "2. Complete code cells marked with `# YOUR CODE HERE`\n",
    "3. Comment or remove lines with `raise NotImplementedError()`\n",
    "4. Run all cells before submission to verify your solutions\n",
    "5. Submit Notebook (.ipynb file) on Moodle with filename using the correct format, e.g., **Assignment_1_JohnDoe_12345678.ipynb**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #e6f3ff; padding: 15px; margin: 10px; border-left: 5px solid #2196F3; border-radius: 3px;\">\n",
    "In this assignment, you will apply the preprocessing and analysis techniques to a real-world dataset. The preprocessing steps here will involve - handling invalid data, removing outliers, dealing with missing values - but adapted to the characteristics of system performance data. Your task is to look for patterns in system behavior that could indicate test system anomalies. Understanding the daily/nightly testing cycles will be crucial for identifying abnormal states.\n",
    "</div>\n",
    "\n",
    "\n",
    "# System Performance Analysis\n",
    "\n",
    "## Background\n",
    "This assignment analyzes performance data from test systems that perform nightly testing of industrial network devices (switches and routers) at Westermo. These test systems validate devices used in critical applications like energy distribution and railway systems.\n",
    "\n",
    "When tests fail, the cause could be:\n",
    "1. Actual issues with the software under test\n",
    "2. Problems in the test framework code\n",
    "3. Hardware setup issues (e.g., wrong cable connections, unpowered devices)\n",
    "4. Server issues (e.g., full disk)\n",
    "\n",
    "The key question is: \"If the test system is in an abnormal state – can we trust the test results?\"\n",
    "\n",
    "### The Dataset\n",
    "The complete dataset consists of 19 CSV files (one per test system), each containing:\n",
    "- About 86,000 samples\n",
    "- Collected over one month\n",
    "- Sampled twice per minute\n",
    "- Over 20 performance metrics\n",
    "\n",
    "Data accessibility and further information: https://github.com/westermo/test-system-performance-dataset\n",
    "\n",
    "**Note:** If you would like to learn more about the dataset, read through the attached pdf file, and check out the dataset link above\n",
    "\n",
    "### Focus of Our Analysis\n",
    "For this assignment, we'll analyze one test system focusing on these key metrics:\n",
    "\n",
    "1. **System Load (load-15m)**\n",
    "   - 15-minute average of system workload\n",
    "   - Shows test execution patterns\n",
    "   - Peaks during night testing, low during day\n",
    "\n",
    "2. **Memory Usage (memory_used_pct)**\n",
    "   - Percentage of total memory used\n",
    "   - Calculated from available/total memory\n",
    "   - Indicates resource utilization\n",
    "\n",
    "3. **CPU Usage (cpu-user)**\n",
    "   - Rate of change in seconds spent on user processes\n",
    "   - Shows changes in processing activity\n",
    "   - Higher values indicate increasing CPU time use\n",
    "\n",
    "4. **Temperature Change (sys-thermal)**\n",
    "   - Rate of change in system temperature\n",
    "   - Optional metric (not on all systems)\n",
    "   - Helps detect system stress\n",
    "\n",
    "5. **Server Status (server-up)**\n",
    "   - System heartbeat indicator\n",
    "   - Values > 0 show server availability\n",
    "   - Critical for validating system operation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial setup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Configure plotting\n",
    "plt.rcParams.update({\n",
    "    'figure.figsize': [12, 8],\n",
    "    'figure.dpi': 150,\n",
    "    'figure.autolayout': True,\n",
    "    'axes.labelsize': 12,\n",
    "    'axes.titlesize': 14,\n",
    "    'font.size': 12\n",
    "})\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"notebook\", font_scale=1.2)\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Task 1.1: Data Loading and Preparation (10 points)\n",
    "\n",
    "Create a function that loads and prepares the system performance data. Your function should:\n",
    "\n",
    "1. Load the data file\n",
    "2. Convert Unix timestamps to datetime\n",
    "3. Calculate memory usage percentage\n",
    "4. Drop unneeded columns \n",
    "\n",
    "Columns in original dataset:\n",
    "```\n",
    "'timestamp', 'load-1m', 'load-5m', 'load-15m', 'sys-mem-swap-total', 'sys-mem-swap-free', 'sys-mem-free', 'sys-mem-cache', 'sys-mem-buffered', 'sys-mem-available', 'sys-mem-total', 'sys-fork-rate', 'sys-interrupt-rate', 'sys-context-switch-rate', 'sys-thermal', 'disk-io-time', 'disk-bytes-read', 'disk-bytes-written', 'disk-io-read', 'disk-io-write', 'cpu-iowait', 'cpu-system', 'cpu-user', 'server-up'\n",
    "```\n",
    "\n",
    "Hint:\n",
    "```python\n",
    "def load_system_data(file_path):\n",
    "    # Read CSV\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Convert timestamp\n",
    "    df['datetime'] = pd.to_datetime(df['timestamp'], unit='s', errors='coerce')\n",
    "\n",
    "    #set index to datetime\n",
    "    df.set_index('datetime', inplace=True)\n",
    "    \n",
    "    # Calculate memory usage\n",
    "    df['memory_used_pct'] = (1 - df['sys-mem-available']/df['sys-mem-total']) * 100\n",
    "    \n",
    "    return df\n",
    "```\n",
    "\n",
    "After loading data and adding ```'memory_used_pct'```, column names in our dataframe should look like this:\n",
    "```\n",
    "['datetime', 'load-15m', 'memory_used_pct', 'cpu-user', 'sys-thermal', 'server-up']\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_system_data(file_path: str) -> pd.DataFrame:\n",
    "    \"\"\"Load and prepare test system performance data.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    file_path : str\n",
    "        Path to the CSV data file\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Processed dataframe with columns:\n",
    "        - datetime: Timestamp (index)\n",
    "        - load-15m: 15-minute load average\n",
    "        - memory_used_pct: Calculated memory usage\n",
    "        - cpu-user: Rate of change in CPU time\n",
    "        - sys-thermal: Temperature change\n",
    "        - server-up: System availability\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    df = pd.read_csv(file_path)\n",
    "    df['datetime'] = pd.to_datetime(df['timestamp'], unit='s',errors='coerce') #coerce converts errous timestamps into NaN\n",
    "    df.set_index('datetime', inplace=True)\n",
    "    df['memory_used_pct'] = (1 - df['sys-mem-available']/df['sys-mem-total'])*100\n",
    "    drop = ['timestamp',\n",
    "            'load-1m',\n",
    "            'load-5m',\n",
    "            'sys-mem-swap-total',\n",
    "            'sys-mem-swap-free',\n",
    "            'sys-mem-free',\n",
    "            'sys-mem-cache',\n",
    "            'sys-mem-buffered',\n",
    "            'sys-mem-available',\n",
    "            'sys-mem-total',\n",
    "            'sys-fork-rate',\n",
    "            'sys-interrupt-rate',\n",
    "            'sys-context-switch-rate',\n",
    "            'disk-io-time',\n",
    "            'disk-bytes-read',\n",
    "            'disk-bytes-written',\n",
    "            'disk-io-read',\n",
    "            'disk-io-write',\n",
    "            'cpu-iowait',\n",
    "            'cpu-system']\n",
    "    df = df.drop(drop, axis=1)\n",
    "    return df\n",
    "\n",
    "    # raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test cell (simply run it)\n",
    "df = load_system_data('system-1.csv')\n",
    "\n",
    "# Check required columns\n",
    "required_cols = ['load-15m', 'memory_used_pct', 'cpu-user', 'sys-thermal', 'server-up']\n",
    "assert all(col in df.columns for col in required_cols), \"Missing required columns\"\n",
    "assert isinstance(df.index, pd.DatetimeIndex), \"Index should be datetime\"\n",
    "assert df['memory_used_pct'].between(0, 100).all(), \"Memory usage should be percentage\"\n",
    "print(\"Basic data structure tests passed!\")\n",
    "\n",
    "print(\"Data Overview:\")\n",
    "print(f\"Time range: {df.index.min()} to {df.index.max()}\")\n",
    "print(f\"Number of samples: {len(df):,}\")\n",
    "print(\"\\nFirst few rows:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1.2: Raw Data Overview Visualization (30 points)\n",
    "\n",
    "Create a comprehensive visualization of the system metrics. You are free to adapt and add more plots, however, your visualization should atleast include:\n",
    "\n",
    "1. **Time Series Overview** (5 points)\n",
    "   - Show all metrics over time\n",
    "   - Highlight server availability status\n",
    "   - Use appropriate alpha and line width\n",
    "   - Add proper labels\n",
    "\n",
    "2. **Daily Distribution** (5 points)\n",
    "   - Create boxplots by hour\n",
    "   - Show daily patterns\n",
    "   - Consider server uptime periods\n",
    "   \n",
    "3. **Correlation Analysis** (5 points)\n",
    "   - Create correlation matrix between metrics\\\n",
    "     (Use seaborn heatmap visualization) \n",
    "\n",
    "4. **Relationship Visualization** (5 points)\n",
    "   - Scatter plot of key metrics\n",
    "   - Hexbin plot for dense areas\n",
    "   - Color scatter points by server status\n",
    "     \n",
    "5. **Layout and Formatting** (5 points)\n",
    "    - Clear titles and labels\n",
    "    - Appropriate color schemes\n",
    "   \n",
    "Hints for visualizations:\n",
    "```python\n",
    "# Correlation heatmap\n",
    "corr_matrix = df[['load-15m', 'memory_used_pct', 'cpu-user', 'sys-thermal', 'server-up']].corr()\n",
    "sns.heatmap(corr_matrix,\n",
    "            annot=True,      # Show correlation values\n",
    "            cmap='coolwarm', # Diverging colormap\n",
    "            center=0,        # Center colormap at 0\n",
    "            fmt='.2f',       # Format coefficients\n",
    "            ax=axes[1, 0])\n",
    "axes[1, 0].set_title('Metric Correlations')\n",
    "\n",
    "# Scatter plot with server status\n",
    "scatter = axes[1, 1].scatter(df['cpu-user'], df['memory_used_pct'],\n",
    "                           c=df['server-up'],  # Color by status\n",
    "                           cmap='RdYlGn',      # Red-Yellow-Green\n",
    "                           alpha=0.5)          \n",
    "plt.colorbar(scatter, ax=axes[1, 1], label='Server Status')\n",
    "axes[1, 1].set_xlabel('CPU Time Rate of Change (seconds)') \n",
    "axes[1, 1].set_title('CPU Time vs Memory Usage')        \n",
    "\n",
    "# Hexbin for density\n",
    "df.plot.hexbin(x='load-15m', y='cpu-user',\n",
    "               gridsize=20,\n",
    "               cmap='YlOrRd',\n",
    "               ax=axes[2, 0])\n",
    "axes[2, 0].set_title('Load vs CPU Usage Density')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "def Time_Series_Overview(df: pd.DataFrame, alpha: float, lable=\"Data\", first=False):\n",
    "    highlight = df['server-up'] != 2\n",
    "\n",
    "    plt.suptitle('Time Series', fontsize=16, fontweight='bold', y=0.995)\n",
    "    plt.subplot(5,1,1)\n",
    "    plt.plot(df.index, df['load-15m'], alpha=alpha, marker='o', linestyle='None', markersize=1, label = lable)\n",
    "    plt.scatter(df.index[highlight], df['load-15m'][highlight], c='red')\n",
    "    plt.ylabel(\"Load Avarage\")\n",
    "    plt.title(\"15m average workload\")\n",
    "    plt.legend(loc='upper right')\n",
    "\n",
    "    plt.subplot(5,1,2)\n",
    "    plt.plot(df.index, df['memory_used_pct'], alpha=alpha, marker='o', linestyle='None', markersize=1, label = lable)\n",
    "    plt.scatter(df.index[highlight], df['memory_used_pct'][highlight], c='red')\n",
    "    plt.title(\"Memory used\")\n",
    "    plt.ylabel(\"Memory [%]\")\n",
    "    plt.legend(loc='upper right')\n",
    "\n",
    "    plt.subplot(5,1,3)\n",
    "    plt.plot(df.index, df['cpu-user'], alpha=alpha, marker='o', linestyle='None', markersize=1, label = lable)\n",
    "    plt.scatter(df.index[highlight], df['cpu-user'][highlight], c='red')\n",
    "    plt.ylabel(\"CPU used\")\n",
    "    plt.title(\"CPU user\")\n",
    "    plt.legend(loc='upper right')\n",
    "\n",
    "    plt.subplot(5,1,4)\n",
    "    plt.plot(df.index, df['sys-thermal'], alpha=alpha, marker='o', linestyle='None', markersize=1, label = lable)\n",
    "    plt.scatter(df.index[highlight], df['sys-thermal'][highlight], c='red')\n",
    "    plt.title(\"System: Temp\")\n",
    "    plt.ylabel(\"Temp Change[°C]\")\n",
    "    plt.legend(loc='upper right')\n",
    "\n",
    "    plt.subplot(5,1,5)\n",
    "    plt.plot(df.index, df['server-up'], alpha=alpha, marker='o', linestyle='None', markersize=1, label = lable)\n",
    "    if(first):\n",
    "        plt.scatter(df.index[highlight], df['server-up'][highlight], c='red', label= \"Server-Down-Periods\")\n",
    "    else:\n",
    "        plt.scatter(df.index[highlight], df['server-up'][highlight], c='red')\n",
    "    plt.ylabel(\"Server Status\")\n",
    "    plt.title(\"Server Status\")\n",
    "    plt.xlabel(\"Datetime\")\n",
    "    plt.legend(loc='lower right')\n",
    "\n",
    "def Time_Series_Removed(df: pd.DataFrame, alpha: float):\n",
    "    highlight = df['server-up'] != 2\n",
    "\n",
    "    plt.suptitle('Time Series', fontsize=16, fontweight='bold', y=0.995)\n",
    "    plt.subplot(5,1,1)\n",
    "    plt.plot(df.index, df['load-15m'], alpha=alpha, marker='x', linestyle='None', markersize=5, label = \"Removed Datapoints\")\n",
    "    plt.scatter(df.index[highlight], df['load-15m'][highlight], c='red')\n",
    "    plt.ylabel(\"Load Avarage\")\n",
    "    plt.title(\"15m average workload\")\n",
    "    plt.legend(loc='upper right')\n",
    "\n",
    "    plt.subplot(5,1,2)\n",
    "    plt.plot(df.index, df['memory_used_pct'], alpha=alpha, marker='x', linestyle='None', markersize=5, label = \"Removed Datapoints\")\n",
    "    plt.scatter(df.index[highlight], df['memory_used_pct'][highlight], c='red')\n",
    "    plt.title(\"Memory used\")\n",
    "    plt.ylabel(\"Memory [%]\")\n",
    "    plt.legend(loc='upper right')\n",
    "\n",
    "    plt.subplot(5,1,3)\n",
    "    plt.plot(df.index, df['cpu-user'], alpha=alpha, marker='x', linestyle='None', markersize=5, label = \"Removed Datapoints\")\n",
    "    plt.scatter(df.index[highlight], df['cpu-user'][highlight], c='red')\n",
    "    plt.ylabel(\"CPU used\")\n",
    "    plt.title(\"CPU user\")\n",
    "    plt.legend(loc='upper right')\n",
    "\n",
    "    plt.subplot(5,1,4)\n",
    "    plt.plot(df.index, df['sys-thermal'], alpha=alpha, marker='x', linestyle='None', markersize=5, label = \"Removed Datapoints\")\n",
    "    plt.scatter(df.index[highlight], df['sys-thermal'][highlight], c='red')\n",
    "    plt.title(\"System: Temp\")\n",
    "    plt.ylabel(\"Temp Change[°C]\")\n",
    "    plt.legend(loc='upper right')\n",
    "\n",
    "    plt.subplot(5,1,5)\n",
    "    plt.scatter(df.index[highlight], df['server-up'][highlight], c='red', label= \"Server-Down-Periods\")\n",
    "    plt.ylabel(\"Server Status\")\n",
    "    plt.title(\"Server Status\")\n",
    "    plt.xlabel(\"Datetime\")\n",
    "    plt.legend(loc='lower right')\n",
    "\n",
    "def Daily_Distribution(df: pd.DataFrame, alpha: float):\n",
    "    plt.suptitle('Daily Distribution', fontsize=16, fontweight='bold', y=0.995)\n",
    "    df[\"hour\"] = df.index.hour\n",
    "    plt.subplot(3, 1, 1)\n",
    "    sns.boxplot(data=df, x='hour', y='load-15m',\n",
    "                patch_artist=True,\n",
    "                boxprops=dict(alpha=alpha),)\n",
    "    plt.title('15m average workload')\n",
    "    plt.ylabel('Load Average')\n",
    "    plt.xlabel('')\n",
    "    plt.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    plt.subplot(3, 1, 2)\n",
    "    sns.boxplot(data=df, x='hour', y='memory_used_pct',\n",
    "                patch_artist=True,\n",
    "                boxprops=dict(alpha=alpha),)\n",
    "    plt.title('Memory Usage')\n",
    "    plt.xlabel('')\n",
    "    plt.ylabel('Memory [%]')\n",
    "    plt.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    plt.subplot(3, 1, 3)\n",
    "    sns.boxplot(data=df, x='hour', y='sys-thermal',\n",
    "                patch_artist=True,\n",
    "                boxprops=dict(alpha=alpha),)\n",
    "    plt.title('System Temperature Change')\n",
    "    plt.ylabel('Temp Change [°C]')\n",
    "    plt.xlabel('Hour of Day (0-23)')\n",
    "    plt.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "def Correlation_Analysis(df: pd.DataFrame):\n",
    "    plt.suptitle('Correlation Analysis', fontsize=16, fontweight='bold', y=0.995)\n",
    "    corr_matrix = df[['load-15m', 'memory_used_pct', 'cpu-user', 'sys-thermal', 'server-up']].corr()\n",
    "    sns.heatmap(corr_matrix,\n",
    "                annot=True,      # Show correlation values\n",
    "                cmap='coolwarm', # Diverging colormap\n",
    "                center=0,        # Center colormap at 0\n",
    "                fmt='.2f',       # Format coefficients\n",
    "                ax=plt.gca())\n",
    "\n",
    "def Relationship_Visualization(df: pd.DataFrame):\n",
    "    plt.suptitle('Relationship Vizualisation', fontsize=16, fontweight='bold', y=0.995)\n",
    "    plt.subplot(2, 2, 1)\n",
    "    scatter = plt.scatter(df['cpu-user'], df['memory_used_pct'],\n",
    "                          c=df['sys-thermal'], cmap='RdYlGn',\n",
    "                          alpha=0.5, s=10)\n",
    "    plt.xlabel('CPU Time Rate of Change')\n",
    "    plt.ylabel('Memory Usage [%]')\n",
    "    plt.title('CPU Time vs Memory Usage')\n",
    "    plt.colorbar(scatter, label='sys-thermal')\n",
    "\n",
    "    plt.subplot(2, 2, 2)\n",
    "    plt.hexbin(df['load-15m'], df['cpu-user'],\n",
    "               gridsize=20, cmap='YlOrRd', mincnt=1)\n",
    "    plt.xlabel('System Load (load-15m)')\n",
    "    plt.ylabel('CPU User')\n",
    "    plt.title('Load vs CPU Usage Density')\n",
    "\n",
    "    plt.subplot(2, 2, 3)\n",
    "    plt.hexbin(df['load-15m'], df['memory_used_pct'],\n",
    "               gridsize=20, cmap='YlGnBu', mincnt=1)\n",
    "    plt.xlabel('System Load (load-15m)')\n",
    "    plt.ylabel('Memory Usage [%]')\n",
    "    plt.title('Load vs Memory Usage Density')\n",
    "\n",
    "    plt.subplot(2, 2, 4)\n",
    "    scatter2 = plt.scatter(df['load-15m'], df['sys-thermal'],\n",
    "                           c=df['cpu-user'], cmap='RdYlGn',\n",
    "                           alpha=0.5, s=10)\n",
    "    plt.xlabel('System Load (load-15m)')\n",
    "    plt.ylabel('Temperature Change [°C]')\n",
    "    plt.title('Load vs Temperature')\n",
    "    plt.colorbar(scatter2, label='CPU user')\n",
    "\n",
    "plt.figure(figsize=(12, 16))\n",
    "Time_Series_Overview(df, alpha=1.0, first=True)\n",
    "plt.show()\n",
    "plt.figure(figsize=(12, 16))\n",
    "Daily_Distribution(df, alpha = 1.0)\n",
    "plt.show()\n",
    "print(\"Boxplots for the 'server-up' and the 'cpu-user' had no meaningful information\")\n",
    "Correlation_Analysis(df)\n",
    "plt.show()\n",
    "Relationship_Visualization(df)\n",
    "plt.show()\n",
    "# raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2.1: Data Preprocessing (20 points)\n",
    "\n",
    "<div style=\"background-color: #e6f3ff; padding: 15px; margin: 10px; border-left: 5px solid #2196F3; border-radius: 3px;\">\n",
    "Here your task is to clean and prepare the system performance data. For that purpose, consider system behavior patterns, particularly the day/night testing cycles.\n",
    "</div>\n",
    "\n",
    "Create a function that handles:\n",
    "\n",
    "1. **Invalid Values** (5 points)\n",
    "   - Remove values outside valid ranges\n",
    "   - Consider system behavior patterns\n",
    "   - Verify server status integrity\n",
    "   -\n",
    "    ```python\n",
    "    valid_ranges = {\n",
    "        'load-15m': (0, 0.5),           # System load\n",
    "        'memory_used_pct': (0, 100),   # Percentage\n",
    "        'cpu-user': (0, 2),            # Rate of change in CPU time\n",
    "        'sys-thermal': (-10, 10),      # Temperature change rate (°C/min)\n",
    "        'server-up': (0, float('inf')) # Server availability\n",
    "    }\n",
    "    ```\n",
    "\n",
    "2. **Duplicate Timestamps** (5 points)\n",
    "   - Identify duplicate readings\n",
    "   - Aggregate using appropriate methods\n",
    "   - Maintain data consistency\n",
    "   \n",
    "3. **Outliers** (5 points)\n",
    "   - Use IQR method for each metric\n",
    "   - Consider day/night differences\n",
    "   - Document removed points\n",
    "   \n",
    "4. **Missing Values** (5 points)\n",
    "   - Handle gaps appropriately\n",
    "   - Consider server status\n",
    "   - Limit interpolation range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers_iqr(data: pd.Series, column: str) -> pd.Series:\n",
    "    \"\"\"Remove outliers using IQR method.\"\"\"\n",
    "    Q1 = data[column].quantile(0.25)\n",
    "    Q3 = data[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    valid_mask = (data[column] >= Q1 - 1.5*IQR) & \\\n",
    "                 (data[column] <= Q3 + 1.5*IQR)\n",
    "    return data[column].where(valid_mask, np.nan)\n",
    "\n",
    "def handle_missing_values(data: pd.DataFrame, column: str,\n",
    "                         max_gap: int = 8) -> pd.Series:\n",
    "    \"\"\"Interpolate missing values with limit.\"\"\"\n",
    "    return data[column].interpolate(\n",
    "        method='linear',\n",
    "        limit=max_gap  # Only fill gaps up to 8 points\n",
    "    )\n",
    "\n",
    "def preprocess_system_data(df: pd.DataFrame):\n",
    "    \"\"\"Preprocess system performance data.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        Raw system performance data with required metrics:\n",
    "        - load-15m\n",
    "        - memory_used_pct\n",
    "        - cpu-user\n",
    "        - sys-thermal (optional)\n",
    "        - server-up\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "        df_original, df_cleaned containing:\n",
    "        - Original data copy\n",
    "        - Cleaned data with:\n",
    "          * Invalid values removed\n",
    "          * Duplicates handled\n",
    "          * Outliers removed\n",
    "          * Missing values interpolated\n",
    "    \"\"\"\n",
    "    # Store original data\n",
    "    df_original = df.copy()\n",
    "    df_cleaned= df.copy()\n",
    "    \n",
    "    # Define valid ranges\n",
    "    valid_ranges = {\n",
    "        'load-15m': (0, 0.5),           # System load\n",
    "        'memory_used_pct': (0, 100),   # Percentage\n",
    "        'cpu-user': (0, 2),            # Rate of change in CPU time\n",
    "        'sys-thermal': (-10, 10),      # Rate of change in °C\n",
    "        'server-up': (0, float('inf')) # Server availability\n",
    "    }\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    # 1. Handle invalid values\n",
    "    for col, (min_val, max_val) in valid_ranges.items():\n",
    "        if col in df_cleaned.columns:\n",
    "            df_cleaned.loc[(df_cleaned[col] < min_val) | (df_cleaned[col] > max_val), col] = np.nan\n",
    "    \n",
    "    # 2. Handle duplicates\n",
    "    df_cleaned = df_cleaned[~df_cleaned.index.duplicated(keep='first')]\n",
    "    \n",
    "    # 3. Remove outliers\n",
    "    for col in ['load-15m', 'memory_used_pct', 'cpu-user', 'sys-thermal']:\n",
    "        df_cleaned[col] = remove_outliers_iqr(df_cleaned, col)\n",
    "    \n",
    "    # 4. Handle missing values\n",
    "    for col in ['load-15m', 'memory_used_pct', 'cpu-user', 'sys-thermal']:\n",
    "        df_cleaned[col] = handle_missing_values(df_cleaned, col, max_gap=8)\n",
    "    return df_original, df_cleaned\n",
    "\n",
    "    # raise NotImplementedError()\n",
    "df_original, df_cleaned = preprocess_system_data(df.copy())\n",
    "\n",
    "def get_removed_values(df_original: pd.DataFrame, df_cleaned: pd.DataFrame):\n",
    "    removed_data = df_original.copy()\n",
    "    \n",
    "    for col in ['load-15m', 'memory_used_pct', 'cpu-user', 'sys-thermal']:\n",
    "        mask = (~df_original[col].isna()) & (df_cleaned[col].isna())\n",
    "        removed_data.loc[~mask, col] = np.nan\n",
    "    return removed_data\n",
    "df_removed = get_removed_values(df_original, df_cleaned)\n",
    "plt.figure(figsize=(12, 16))\n",
    "Time_Series_Overview(df_cleaned, 0.9, \"cleaned Data\")\n",
    "Time_Series_Removed(df_removed, 0.4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions\n",
    "\n",
    "You may use these helper functions in your implementation:\n",
    "\n",
    "```python\n",
    "def remove_outliers_iqr(data: pd.Series, column: str) -> pd.Series:\n",
    "    \"\"\"Remove outliers using IQR method.\"\"\"\n",
    "    Q1 = data[column].quantile(0.25)\n",
    "    Q3 = data[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    valid_mask = (data[column] >= Q1 - 1.5*IQR) & \\\n",
    "                 (data[column] <= Q3 + 1.5*IQR)\n",
    "    return data[column].where(valid_mask, np.nan)\n",
    "\n",
    "def handle_missing_values(data: pd.DataFrame, column: str,\n",
    "                         max_gap: int = 8) -> pd.Series:\n",
    "    \"\"\"Interpolate missing values with limit.\"\"\"\n",
    "    return data[column].interpolate(\n",
    "        method='linear',\n",
    "        limit=max_gap  # Only fill gaps up to 8 points\n",
    "    )\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test cell for Task 2.1 - Preprocessing\n",
    "df_original, df_cleaned = preprocess_system_data(df)\n",
    "assert isinstance(df_original, pd.DataFrame), \"Should return original dataframe\"\n",
    "assert isinstance(df_cleaned, pd.DataFrame), \"Should return cleaned dataframe\"\n",
    "assert df_cleaned['cpu-user'].min() >= 0 and df_cleaned['cpu-user'].max() <= 2, \"CPU rate should be between 0 and 2\"\n",
    "print(\"Basic preprocessing tests passed!\")\n",
    "\n",
    "print(\"Data Preprocessing Results:\")\n",
    "print(f\"Original shape: {df_original.shape}\")\n",
    "print(f\"Cleaned shape: {df_cleaned.shape}\")\n",
    "\n",
    "print(\"\\nMissing Values Summary:\")\n",
    "print(df_cleaned.isnull().sum())\n",
    "\n",
    "print(\"\\nValue Ranges (Cleaned):\")\n",
    "for col in ['load-15m', 'memory_used_pct', 'cpu-user', 'sys-thermal', 'server-up']:\n",
    "    print(f\"\\n{col}:\")\n",
    "    print(df_cleaned[col].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2.2: Raw vs Cleaned Data Comparison by Visualization (30 points)\n",
    "\n",
    "<div style=\"background-color: #e6f3ff; padding: 15px; margin: 10px; border-left: 5px solid #2196F3; border-radius: 3px;\">Create comprehensive comparisons between the raw and cleaned data versions.\n",
    "</div>\n",
    "\n",
    "Requirements:\n",
    "1. **Time Series Comparison** (10 points)\n",
    "   - Plot original and cleaned data on same axes\n",
    "   - Use alpha to show overlaps\n",
    "   - Highlight removed outliers\n",
    "   - Include server status representation\n",
    "\n",
    "2. **Distribution Analysis** (5 points)\n",
    "   - Compare original vs cleaned distributions\n",
    "   - Show effects of preprocessing\n",
    "   - Demonstrate quality improvements\n",
    "\n",
    "3. **Impact Documentation** (5 points)\n",
    "   - Document key statistics before/after\n",
    "   - Explain preprocessing effects\n",
    "   - Justify data cleaning decisions\n",
    "\n",
    "Note: You can also add further more visualizations, in addition to the ones above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_data_versions(df_original: pd.DataFrame,\n",
    "                         df_cleaned: pd.DataFrame):\n",
    "    \"\"\"Compare original and cleaned data versions using visualizations.\n",
    "    \n",
    "    Creates multiple plots comparing the original and cleaned data:\n",
    "    - Time series comparison of all metrics\n",
    "    - Daily patterns before and after cleaning\n",
    "    - Correlation analysis\n",
    "    - Distribution comparisons\n",
    "    \n",
    "    Parameters:\n",
    "    df_original: Original unprocessed data\n",
    "    df_cleaned: Cleaned and processed data\n",
    "    \"\"\"\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    # Create comparison visualizations\n",
    "    plt.figure(figsize=(12, 16))\n",
    "    Time_Series_Overview(df_cleaned, 0.9,\"Cleaned Data\")\n",
    "    Time_Series_Overview(df_original, 0.4, \"Original Data\", True)\n",
    "    plt.show\n",
    "    plt.figure(figsize=(12, 16))\n",
    "    Daily_Distribution(df_original, 0.4)\n",
    "    plt.figure(figsize=(12, 16))\n",
    "    Daily_Distribution(df_cleaned, 0.9)\n",
    "\n",
    "    plt.figure()\n",
    "    Relationship_Visualization(df_original)\n",
    "    plt.figure()\n",
    "    Relationship_Visualization(df_cleaned)\n",
    "    # Calculate comparison statistics\n",
    "    # Document data cleaning impact\n",
    "    # raise NotImplementedError()\n",
    "compare_data_versions(df_original,  df_cleaned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- ## Task 2.3: Cleaned Data Analysis (24 points)\n",
    "\n",
    "Based on your cleaned data visualizations from the previous task, analyze the system performance patterns. Your answers should reflect the improved data quality after preprocessing.\n",
    "\n",
    "1. Server Availability Patterns:\\\n",
    "a_) Server uptime shows regular testing patterns\\\n",
    "b_) Maintenance windows (server-down periods) occur at consistent times\n",
    "\n",
    "2. System Performance:\\\n",
    "c_) High load periods (load-15m) align with server uptime\\\n",
    "d_) High memory usage periods coincide with increased CPU time rate\\\n",
    "e_) Temperature change rate increases during high system load periods\n",
    "\n",
    "3. System Health:\\\n",
    "f_) Server status shows regular planned downtime periods\\\n",
    "g_) System load shows no sustained periods near maximum values (>0.4)\\\n",
    "h_) System load frequently reaches peak values (>0.4) during test execution\n",
    "\n",
    "4. Test Result Reliability:\\\n",
    "i_) Load average remains stable during test execution periods\\\n",
    "j_) Memory usage stays within normal operating range (no spikes) during tests\\\n",
    "k_) Server availability is consistent throughout test cycles -->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Task 2.3: Cleaned Data Analysis (24 points)\n",
    "\n",
    "Based on your visualizations, analyze the system performance patterns.\n",
    "\n",
    "1. Test Execution Patterns:\\\n",
    "a_) System load shows clear day/night testing cycles\n",
    "\n",
    "2. System Performance:\\\n",
    "b_) High load periods (load-15m) align with increased Memory usage\\\n",
    "c_) High memory usage periods coincide with increased CPU usage rate of change\\\n",
    "d_) Temperature change rate increases during high system load periods\n",
    "\n",
    "3. Resource Utilization:\\\n",
    "e_) Memory usage consistently increases at test start and gradually decreases towards test completion\\\n",
    "f_) System load stays within reasonable limits (<0.4) during normal operation\n",
    "\n",
    "4. System Behavior:\\\n",
    "g_) Memory usage returns to idle state levels (around 5-6%) between test cycles\\\n",
    "h_) Load, memory, and CPU metrics collectively show clear patterns distinguishing between test execution and idle periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answers and reasoning below. For each statement, first set the boolean value \n",
    "# then explain your reasoning based on the visualizations.\n",
    "\n",
    "# Test Execution Patterns\n",
    "a_ = True\n",
    "# Your reasoning here\n",
    "\"\"\"\n",
    "In the daily distribution it can clearly be seen that there are higher median 15minute load cycles that\n",
    "during the day hours from 7am to 6pm. Therefore a clearly day/night cycle can be seen.\n",
    "In addition to the higher average value also the Interquartile Range of the night hours\n",
    "is situated at higher 15minute load values.\n",
    "\"\"\"\n",
    "# System Performance\n",
    "b_ = True\n",
    "# Your reasoning here\n",
    "\"\"\"\n",
    "This can also be seen very clearly out of the daily distribution and the time series,\n",
    "how the boxplots are situated. With the higher 15 minute average load the boxplots\n",
    "(Interquartile distance & median) also the memory usage increases at night.\n",
    "In the timeseries there are also intervals with higher load and Memory usage which align\n",
    "(appear at the in the same measurement (datetime indexes match))\n",
    "\"\"\"\n",
    "c_ = True\n",
    "# Your reasoning here\n",
    "\"\"\"\n",
    "This is also true and can also be verified in the timeseries. There it is clearly\n",
    "visible how the higher memory usage periodes match the datetime indexes from the\n",
    "higher CPU usage range changes.\n",
    "\"\"\"\n",
    "d_ = False\n",
    "# Your reasoning here\n",
    "\"\"\"\n",
    "Out of the drawn plots i could not see a correlation between the load and the change of the\n",
    "sys-thermal parameter. Therefore its visible that the systems thermal change is distributed on three\n",
    "rows in parallel. I think this is caused by the usage of different devices which have different offsets\n",
    "for the thermal change.\n",
    "The distribution in the scatter plot also indicates that there is no correlation between load and\n",
    "sys-thermal.\n",
    "\"\"\"\n",
    "# Resource Utilization\n",
    "e_ = False\n",
    "# Your reasoning here\n",
    "\"\"\"\n",
    "The test memory does instantly rais with the test start. Not toward the beginning.\n",
    "The memory increases when the test run has started and increases constantly with the test duration.\n",
    "When the test has finished the memory usage does not gradually decreases it instantly decreases\n",
    "again.\n",
    "This can be seen out of the time series.\n",
    "\"\"\"\n",
    "f_ = True\n",
    "# Your reasoning here\n",
    "\"\"\"\n",
    "This can be seen in the daily distribution, the time series and the relationship plots of the\n",
    "dataset. In the uncleand dataset only some outlayers are above the 0,4 load limitation.\n",
    "\"\"\"\n",
    "# System Behavior\n",
    "g_ = True\n",
    "# Your reasoning here\n",
    "\"\"\"\n",
    "This can be seen in the time series and the hexbin plot. The idel level\n",
    "of the memory usage is often reached (darker color in the idel stage at the\n",
    "hexbin plot) and also at the time series when there is no 15 minute\n",
    "load (idle state) the memory usage is at 5-6 %.\n",
    "\"\"\"\n",
    "h_ = True \n",
    "# Your reasoning here\n",
    "\"\"\"\n",
    "This is also clearly visible in the time series where load, the CPU usage changing rate and\n",
    "the memory consumption have matching periods of higher values. Those are the test periods.\n",
    "Between two test periodes all paramaters are reduced again to there idle values = idle periode.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test cell - DO NOT MODIFY\n",
    "for var in ['a_', 'b_', 'c_', 'd_', 'e_', 'f_', 'g_', 'h_']:\n",
    "    assert var in locals(), f\"Missing answer for {var}\"\n",
    "    assert isinstance(locals()[var], bool), f\"Answer for {var} must be True or False\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra Tasks: Interactive Visualizations (15 Bonus Points)\n",
    "\n",
    "Leverage Altair to create interactive visualizations based on the cleaned system performance data. Before you start, review the **Interactive Plotting** tutorial to familiarize yourself with Altair's capabilities for crafting interactive plots.\n",
    "\n",
    "Feel free to experiment and design different types of interactive visualizations that effectively represent the data, in addition to the tasks described below.\n",
    "\n",
    "**Possible visualization ideas:**\n",
    "\n",
    "- **Interactive Time-Series Charts**: Plot CPU and memory usage over time with zoom and pan functionalities.\n",
    "- **Scatter Plots with Tooltips**: Explore relationships between performance metrics by displaying detailed information on hover.\n",
    "- **Heatmaps and Correlation Matrices**: Visualize correlations with interactive elements that highlight specific data points.\n",
    "- **Combined Dashboards**: Create a dashboard featuring multiple interactive charts for a holistic view of system performance.\n",
    "\n",
    "Be creative and innovative in your approach to make the visualizations both informative and engaging.\n",
    "\n",
    "### ET1: Basic Interactive Time Series (5 points)\n",
    "Create an interactive time series visualization that includes:\n",
    "1. System load over time with zoom/pan capabilities\n",
    "2. Tooltips showing metric values\n",
    "3. Server status indicated by color\n",
    "\n",
    "Hint:\n",
    "```python\n",
    "\n",
    "import altair as alt\n",
    "\n",
    "# Enable the rendering of charts\n",
    "alt.renderers.enable('default')\n",
    "# Set a maximum number of rows for Altair\n",
    "alt.data_transformers.enable('default', max_rows=None)\n",
    "\n",
    "def create_basic_interactive(df):\n",
    "    # Base chart with zoom\n",
    "    chart = alt.Chart(df.reset_index()).mark_line().encode(\n",
    "        x='datetime:T',\n",
    "        y=alt.Y('cpu-user', \n",
    "                title='CPU Time Rate of Change (seconds)'),  # Updated title\n",
    "        color=alt.Color('server-up:Q', \n",
    "                       scale=alt.Scale(scheme='redyellowgreen')),\n",
    "        tooltip=['datetime:T', \n",
    "                alt.Tooltip('cpu-user', \n",
    "                           title='CPU Time Change'), \n",
    "                'server-up']\n",
    "    ).interactive()\n",
    "    \n",
    "    return chart\n",
    "```\n",
    "\n",
    "Note: Make sure to install required packages:\n",
    "```python\n",
    "# Install packages if needed:\n",
    "# pip install altair altair_saver vega_datasets\n",
    "# or\n",
    "# conda install -c conda-forge altair altair_saver vega_datasets\n",
    "\n",
    "# altair_saver package - to allow saving visualizations.\n",
    "# vega_datasets - to provide example datasets\n",
    "# Note: Above two packages (altair_saver and vega_datasets) are not necessary here but relevant for the interactive tutorial.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "import altair as alt\n",
    "\n",
    "# Enable the rendering of charts\n",
    "alt.renderers.enable('default')\n",
    "# Set a maximum number of rows for Altair\n",
    "alt.data_transformers.enable('default', max_rows=None)\n",
    "\n",
    "def create_basic_interactive(df: pd.DataFrame):\n",
    "    # Base chart with zoom\n",
    "    chart = alt.Chart(df.reset_index()).mark_line().encode(\n",
    "        x='datetime:T',\n",
    "        y=alt.Y('cpu-user', \n",
    "                title='CPU Time Rate of Change (seconds)'),  # Updated title\n",
    "        color=alt.Color('server-up:Q', \n",
    "                       scale=alt.Scale(scheme='redyellowgreen')),\n",
    "        tooltip=['datetime:T', \n",
    "                alt.Tooltip('cpu-user', \n",
    "                           title='CPU Time Change'), \n",
    "                'server-up']\n",
    "    ).interactive()\n",
    "    \n",
    "    return chart\n",
    "\n",
    "create_basic_interactive(df)\n",
    "# raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### ET2: Linked Views (5 points)\n",
    "Create two linked interactive visualizations:\n",
    "1. Load vs Memory usage scatter plot\n",
    "2. Corresponding histogram of selected data points\n",
    "3. Implement brushing to highlight points\n",
    "\n",
    "Hint:\n",
    "```python\n",
    "def create_linked_views(df):\n",
    "    # Create selection\n",
    "    brush = alt.selection_interval()\n",
    "    \n",
    "    # Scatter plot\n",
    "    scatter = alt.Chart(df).mark_point().encode(\n",
    "        x='load-15m',\n",
    "        y='memory_used_pct',\n",
    "        color=alt.condition(brush, 'server-up:Q', alt.value('lightgray'))\n",
    "    ).add_selection(brush)\n",
    "    \n",
    "    # Histogram for selected data\n",
    "    hist = alt.Chart(df).mark_bar().encode(\n",
    "        x='load-15m',\n",
    "        y='count()'\n",
    "    ).transform_filter(brush)\n",
    "    \n",
    "    return scatter & hist  # Stack vertically\n",
    "```\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "def create_linked_views(df: pd.DataFrame):\n",
    "    # Create selection\n",
    "    brush = alt.selection_interval()\n",
    "    \n",
    "    # Scatter plot\n",
    "    scatter = alt.Chart(df).mark_point().encode(\n",
    "        x='load-15m',\n",
    "        y='memory_used_pct',\n",
    "        color=alt.condition(brush, 'server-up:Q', alt.value('lightgray'))\n",
    "    ).add_params(brush)\n",
    "    \n",
    "    # Histogram for selected data\n",
    "    hist = alt.Chart(df).mark_bar().encode(\n",
    "        x='load-15m',\n",
    "        y='count()'\n",
    "    ).transform_filter(brush)\n",
    "    \n",
    "    return scatter & hist  # Stack vertically\n",
    "create_linked_views(df)\n",
    "# raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ET3: Advanced Dashboard (5 points)\n",
    "Create a comprehensive dashboard with:\n",
    "1. Time series with selectable time range\n",
    "2. Metric comparison scatter plot\n",
    "3. Summary statistics for selected period\n",
    "4. Interactive filtering across all views\n",
    "\n",
    "Points awarded for:\n",
    "- Creative use of Altair features\n",
    "- Effective interaction design\n",
    "- Clear visual communication\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "raise NotImplementedError()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
